# Programación Dinámica

## Índice

## Secuencia Fibonacci

La solución más trivial para calcular el n-ésimo número de la secuencia de Fibonacci es la siguiente:

```python
def fibonacci(n):
    if n == 0:
        return 0
    if n == 1:
        return 1
    return fibonacci(n-1) + fibonacci(n-2)
```

Esta solución tiene complejidad $O(2^n)$ ya que para calcular el n-ésimo número se calculan los números n-1 y n-2, y para calcular el n-1 se calculan los números n-2 y n-3, y así sucesivamente.

Cómo podemos evitar recalcular los mismos números una y otra vez?

```python
def fibonacci_memorioso(n):
    M_FIB = [None] * (n+1)
    return fibonacci_memorioso_rec(n, M_FIB)

def fibonacci_memorioso_rec(n, M_FIB):
    if n == 0:
        return 0
    if n == 1:
        return 1
    if M_FIB[n-1] is None:
        M_FIB[n-1] = fibonacci_memorioso_rec(n-1, M_FIB)
    if M_FIB[n-2] is None:
        M_FIB[n-2] = fibonacci_memorioso_rec(n-2, M_FIB)
    M_FIB[n] = M_FIB[n-1] + M_FIB[n-2]
    return M_FIB[n]
```

A este tipo de soluciones se las llama "top-down" ya que se va construyendo la solución desde el n-ésimo elemento. Suelen ser difíciles de entender en problemas más complejos ya que el flujo de ejecución puede no ser lineal (imagínese una secuencia donde el i-ésimo valor es determinado por el elemento i-3), y la recursión puede ser difícil de seguir. Además, la recursividad implica mayor uso de memoria y puede llevar a un stack overflow si la profundidad de la recursión es muy grande.

Otra forma de resolver el problema es de forma "bottom-up", que consiste en ir construyendo la solución desde el primer elemento hasta el n-ésimo, iterativamente:

```python
def fib_iterativo(n):
    M_FIB = [None] * (n+1)
    M_FIB[0] = 0
    M_FIB[1] = 1
    for i in range(2, n+1):
        M_FIB[i] = M_FIB[i-1] + M_FIB[i-2]
    return M_FIB[n]
```

En las soluciones "bottom-up" es mucho más fácil seguir el flujo de ejecución y en consecuencia, más fácil de calcular la complejidad. Al ser PD una técnica de diseño que aplica una lógica inductiva, son más naturales e intuitivas las soluciones iterativas: una vez obtenida la ecuación de recurrencia, es muy sencillo implementarlo.

Todo esto nos trae también ventajas a la hora de aplicar optimizaciones de memoria. Podemos mejorar la solución propuesta de la siguiente manera, teniendo en cuenta que no necesitamos guardar todos los valores de la secuencia, sino sólo los dos últimos:

```python
def fib_iterativo_optimizado(n):
    if n == 0:
        return 0
    if n == 1:
        return 1
    anterior = 0
    actual = 1
    for i in range(1, n):
        siguiente = anterior + actual
        anterior = actual
        actual = siguiente
    return actual
```

A diferencia de la otra solución que ocupaba $O(n)$ de memoria, esta solución ocupa $O(1)$ de memoria.

### Memoization (Memorización)

- Memoization es la técnica de guardar los resultados previamente calculados.
- En este caso nos permitió reducir la complejidad de $O(2^n)$ a $O(n)$.

## Solución por Programación Dinámica

- Se basa en la idea de Memoization
- Construye iterativamente las soluciones a los subproblemas hasta llegar a la solución del problema original
- Se consigue la solución al problema gracias a que tenemos una forma de construir la solución a problemas más grandes en función de problemas más pequeños
- Establecemos una lógica inductiva: "Si tengo la solución a todos los problemas anteriores(casos más pequeños), ¿cómo puedo utilizarlos para construir la que busco?"

## Problema de Scheduling con pesos

Tengo un aula donde quiero dar harlas. Las charlas tienen horario de inicio y fin, y un peso asociado que indica el valor de la charla. No puedo dar dos charlas al mismo tiempo. *¿Cuál es la mayor cantidad de peso que puedo obtener?* Podemos preguntarnos si se podrá resolver con un algoritmo greedy, les adelanto que no es el caso.

Un buen punto de partida es tratar de ordenar las charlas con algún criterio, de forma que nos permita partir el problema en subproblemas más pequeños que efectivamente nos sirvan para problemas más grandes. Probemos ordenarlos por horario de fin:

![scheduling_con_pesos_1](imagenes/scheduling_con_pesos_1.png)

Una forma sencilla de atacar estos problemas es definir qué elecciones puedo hacer, y qué implica cada elección. En nuestro caso, si elijo una charla, no puedo elegir las charlas que se superponen con ella. Si decidimos dar la charla 6, nuestra opción queda acotada por las charlas 1 a 4, ya que las otras se ven superpuestas con charla 6.

Si definimos una función $p(i)$ que nos da el rango de charlas anteriores que podemos elegir si decidimos dar la charla i:

![scheduling_con_pesos_2](imagenes/scheduling_con_pesos_2.png)

Como todas las charlas previas a la charla i que finalicen antes que empiece ella serán compatibles con ella, indicaremos sólo la última entre el rango. De esta forma, podemos ahorrar tener que recorrer todas las charlas para encontrar las compatibles.

Estos rangos son nuestros subproblemas: teniendo todas las charlas originales, podemos decidir dar la última charla o no. Si decidimos darla, el valor de la solución será el $valor_i$ más el valor de la solución del rango compatible con ella. Si decidimos no darla, el valor de la solución será el valor de la solución del rango 1 hasta i-1. Lo que debemos hacer es comparar estos dos valores y quedarnos con el mayor.

Formalizando esto, definimos la función $OPT(i)$ como el valor de la solución óptima para las charlas 1 hasta i. La solución al problema original será $OPT(n)$, donde n es la cantidad de charlas.

La ecuación de recurrencia es la siguiente:

$OPT(i) = max(valor_i + OPT(p(i)), OPT(i-1))$

### Solución recursiva

```python
# i es el índice de la charla actual, considerando el primero como 1
# Considerando que los valores están ordenadas por horario de fin
def scheduling_rec(valores, p, i):
    if i == 0:
        return 0
    return max(valores[i-1] + scheduling_rec(valores, p, p[i-1]),
        scheduling_rec(valores, p, i-2))
```

### Solución memoriosa

```python
def scheduling_memorioso(valores, p, i):
    M_OPT = [None] * (i+1)
    return scheduling_memorioso_rec(valores, p, i, M_OPT)

def scheduling_memorioso_rec(valores, p, i, M_OPT):
    if i == 0:
        return 0
    if M_OPT[i-1] is None: # Si aún no calculamos la solución para i-1
        M_OPT[i-1] = scheduling_memorioso_rec(valores, p, i-1, M_OPT)
    if M_OPT[p(i)] is None: # Si aún no calculamos la solución para p(i)
        M_OPT[p(i)] = scheduling_memorioso_rec(valores, p, p[i], M_OPT)
    M_OPT[i] = max(valores[i-1] + M_OPT[p(i)-1], M_OPT[i-2])
    return M_OPT[i]
```

### Solución iterativa

```python
def scheduling_iterativo(valores, p, n):
    if n == 0:
        return 0
    M_OPT = [0] * (n+1)
    M_OPT[0] = 0
    for i in range(1, n+1):
        M_OPT[i] = max(valores[i-1] + M_OPT[p(i)], M_OPT[i-1])
    return M_OPT[n]
```

### Cómo obtener el conjunto de charlas

La solución más trivial sería ir guardando el conjunto de charlas a dar en cada subproblema, pero esto implica una complejidad de $O(n)$ en cada una de ellas, lo que nos llevaría a una complejidad de $O(n^2)$ en total.

Lo que podemos hacer es ver $M\_OPT$ y comparar $M\_OPT[i]$ con $M\_OPT[i-1]$. Si son iguales, la charla i no fue considerada, y si son distintos, la charla i fue considerada. Haciendo este recorrido desde n hasta 1, podemos obtener el conjunto de charlas a dar en $O(n)$.

*En realidad que sean iguales no necesariamente implica que no fue considerada, ya que puede haber más de una solución óptima.*

## Características de Programación Dinámica

- Explora todas las posibles soluciones sin repetir cálculos, utilizando la memorización. Nos ayuda a evitar explorar un espacio exponencial de soluciones por fuerza bruta.
- Descompone el problema en subproblemas más pequeños que permitan construir la solución al problema original

## Cómo identificar problemas que se pueden resolver con Programación Dinámica

- Hay un número polinomial de subproblemas
- La solución al problema original puede ser construida a partir de las soluciones a los subproblemas
- Hay un orden natural de los subproblemas de menor a mayor, de forma que los subproblemas mayores pueden ser resuelto a partir de los menores

## Cómo encontrar la solución usando Programación Dinámica

- Necesitamos:
    - La forma que tienen los subproblemas
    - La forma en que los subproblemas se componen para solucionar subproblemas más grandes
    - Definir el orden en que se resuelven los subproblemas

## Problema de los 2 escalones

Dada una escalera de n escalones, se puede subir de a 1 o 2 escalones. *¿De cuántas formas se puede subir la escalera?*

Si la escalera tiene 0 escalones, hay 1 forma de subirla (no subir).

Si tiene 1 escalón, hay 1 forma de subirla (subir 1 escalón).

Si tiene 2 escalones, hay 2 formas de subirla (subir 1 escalón dos veces o subir 2 escalones de una vez).

Si definimos $OPT(i)$ como la cantidad de formas de subir una escalera de i escalones:

Para una escalera con n escalones, si subimos 1 escalón para llegar a n, tendremos $OPT(n-1)$ formas de subir la escalera. Si subimos 2 escalones para llegar a n, tendremos $OPT(n-2)$ formas de subir la escalera.

Por lo tanto, $OPT(n) = OPT(n-1) + OPT(n-2)$.

*A veces surge la siguiente duda entre los alumnos: en OPT(n-1), que equivale a OPT(n-2) + OPT(n-3), también estamos considerando OPT(n-2), que ya consideramos en OPT(n-2). ¿No estamos repitiendo cálculos? La respuesta a esta duda es que hay que repetirlos; consideremos OPT(2) = OPT(1) + OPT(0) = OPT(0) + OPT(0). Pueden ver que OPT(0) aparece 2 veces, y OPT(2) es 2, el valor correcto. OPT(n-1) y OPT(n-2) son 2 árboles distintos.*

## Problema de los 3 escalones

Dada una escalera de n escalones, se puede subir de a 1, 2 o 3 escalones. *¿De cuántas formas se puede subir la escalera?*

Si la escalera tiene 0 escalones, hay 1 forma de subirla (no subir).

Si tiene 1 escalón, hay 1 forma de subirla (subir 1 escalón).

Si tiene 2 escalones, hay 2 formas de subirla (subir 1 escalón dos veces o subir 2 escalones de una vez).

Si tiene 3 escalones, hay 4 formas de subirla (subir 1 escalón tres veces, subir 1 escalón y 2 escalones, subir 2 escalones y 1 escalón, subir 3 escalones de una vez).

Si definimos $OPT(i)$ como la cantidad de formas de subir una escalera de i escalones:

Para una escalera con n escalones, si subimos 1 escalón para llegar a n, tendremos $OPT(n-1)$ formas de subir la escalera. Si subimos 2 escalones para llegar a n, tendremos $OPT(n-2)$ formas de subir la escalera. Si subimos 3 escalones para llegar a n, tendremos $OPT(n-3)$ formas de subir la escalera.


Por lo tanto, $OPT(n) = OPT(n-1) + OPT(n-2) + OPT(n-3)$.


